{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNevSl3y8mBM7Ck9LVQtRg2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee95292/5thHackathon_bookerrow/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "VzV-pnGmbMp9",
        "outputId": "36c4f9d8-e5be-42b7-8af0-a854c0c0b1fe"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def AND(x1,x2): # perceptron\n",
        "  w1,w2,theta = 0.5,0.5,0.7 #w1, w2 weights\n",
        "  value = x1*w1 + x2*w2 + 0 # bias = 0\n",
        "\n",
        "  #return identity(value) #activation function\n",
        "\n",
        "  if(value > theta): #activation function\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def OR(x1,x2):# perceptron\n",
        "  w1,w2,theta = 0.5,0.5,0\n",
        "  value = x1*w1 + x2*w2\n",
        "\n",
        "  if(value > theta):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def NAND(x1, x2):# perceptron\n",
        "  w1,w2,theta = -0.5, -0.5, -0.7\n",
        "  value = x1*w1 + x2*w2\n",
        "\n",
        "  if(value > theta):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def XOR(x1,x2):# perceptron\n",
        "  return AND(NAND(x1,x2), OR(x1,x2))\n",
        "\n",
        "\n",
        "print(XOR(0,0), XOR(0,1), XOR(1,0), XOR(1,1))\n",
        "\n",
        "test_x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "test_y = [0, 1, 1, 0]\n",
        "\n",
        "print(\"{} OR {} = {}\".format(x[0], x[1], 1))\n",
        "\n",
        "for i in range(4):\n",
        "  print(\"{} XOR {} = {}\".format(test_x[i][0], test_x[i][1], XOR(test_x[i][0], test_x[i][1])))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-4968523cae90>\"\u001b[0;36m, line \u001b[0;32m78\u001b[0m\n\u001b[0;31m    W1, B1, W2, B2, W3, B3 =\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POXN9VdKwUn_"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Affine:\n",
        "  def __init__(self, W, B):\n",
        "    pass# TODO\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "\n",
        "  def backward(self):\n",
        "    # self.dW = ...\n",
        "    # self.dB = ...\n",
        "    # dx\n",
        "    pass # 구현 skip \n",
        "\n",
        "  def update(self, learning_rate):\n",
        "    # self.W = self.W - learning_rate * self.dW\n",
        "    # self.B = self.B - learning_rate * self.dB\n",
        "    pass # 구현 skip\n",
        "\n",
        "class Sigmoid:\n",
        "  def forward(self, x):\n",
        "    return 1 / (1 + np.exp(x))\n",
        "\n",
        "class ReLU:\n",
        "  def forward(self, x):\n",
        "    return max(0, x)\n",
        "\n",
        "class Identity:\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "W1, B1, W2, B2, W3, B3 = # TODO\n",
        "layers = # TODO\n",
        "\n",
        "x = [0, 1]\n",
        "layers = [Affine(W1,B1),Sigmoid(x),Affine(W2,B2),ReLU(x),Affine(W3,B3),Identify(x)]\n",
        "for layer in layers:\n",
        "  x = layer.forward(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTHGrXChpYUv",
        "outputId": "4ea05364-f44b-4914-e1c0-82fb98f8d388"
      },
      "source": [
        "import numpy as np\n",
        "a = np.array([[1, 2], [3, 4]])\n",
        "print(a)\n",
        "\n",
        "#a + 1 # broad casting\n",
        "b = np.array([1, 0])\n",
        "print(b)\n",
        "print(a + b) # broad casting\n",
        "print(a.shape)\n",
        "print(b.shape) #row vector, col vector\n",
        "a = np.array([1, 2])\n",
        "b = np.array([2, 3])\n",
        "print(np.dot(a, b)) # 행렬곱\n",
        "a = a.reshape(2, 1)\n",
        "b = b.reshape(1, 2)\n",
        "print(np.dot(a, b))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "[1 0]\n",
            "[[2 2]\n",
            " [4 4]]\n",
            "(2, 2)\n",
            "(2,)\n",
            "8\n",
            "[[2 3]\n",
            " [4 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhA4Cf65u99B",
        "outputId": "3eb0012f-e80c-44a1-ff65-60b8624e653d"
      },
      "source": [
        "import numpy as np\n",
        "print(np.exp(1))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.718281828459045\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}